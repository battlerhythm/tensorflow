{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.1 MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/battlerhythm/tensorflow/blob/master/6.1%20MNIST.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "35jkunKlCmdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "9664c2cc-ea5b-4920-86b2-ca882a9c788d"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-df6c3c653ca2>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ti0eXaGlHyDJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 28x28 pixel 이므로 784개의 특징으로 이뤄져 있다고도 할 수 있습니다.\n",
        "# 그리고 레이블은 0부터 9까지이니 10개의 분류로 나누어 질 수 있습니다.\n",
        "# 이미지를 하나씩 학습시키는것 보다 여러개를 한꺼번에 학습시키는 쪽이 효과가 좋지만,\n",
        "# 그만큼 많은 메모리와 높은 컴퓨팅 성능이 뒷받침돼야 합니다.\n",
        "# 따라서 일반적으로 데이터를 적당한 크기로 잘라서 학습시키는데, 이것을 미니배치(minibatch)라고 합니다.\n",
        "# X와 Y 코드에서 텐서의 첫번째 차원이 None으로 되어 있는데,\n",
        "# 이자리에는 한번에 학습시킬 MNIST 이미지의 개수를 지정하는 값이 들어갑니다.\n",
        "# 원하는 배치 크기로 정확히 명시해줘도 되지만, 한 번에 학습할 개수를 계속 바꿔가면서 실험해보려는 경우에는\n",
        "# None으로 넣어주면 텐서플로가 알아서 계산합니다.\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "# 784 Features -> 256\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "b1 = tf.Variable(tf.zeros([256]))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
        "\n",
        "# 256 -> 256\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "b2 = tf.Variable(tf.zeros([256]))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
        "\n",
        "# 256 -> 10 Label\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "b3 = tf.Variable(tf.zeros([10]))\n",
        "model = tf.matmul(L2, W3) + b3\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "# train_op = optimizer.minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DYY9Ccl3Jn5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "41a07e69-4dbc-449c-8044-50d95dd027a7"
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# 학습데이터 전체를 한 바퀴 도는 것을 에포크(epoch)라고합니다.\n",
        "batch_size = 100\n",
        "num_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "# 학습데이터 전체를 15번 반복 학습한다. 15 epoch\n",
        "for epoch in range(15):\n",
        "    total_cost = 0\n",
        "    \n",
        "    for i in range(num_batch):\n",
        "        # 한번에 batch_size만큼 train시키고, num_batch만큼 반복함.\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
        "        \n",
        "        # 매 배치마다 계산된 cost값을 합하고, 나중에 num_batch로 나누어 평균 Cost값을 계산하는데 사용한다\n",
        "        total_cost += cost_val\n",
        "        \n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost =' '{:.3f}'.format(total_cost / num_batch))\n",
        "    \n",
        "print('최적화 완료')\n",
        "\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "print('정확도:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Avg. cost =0.403\n",
            "Epoch: 0002 Avg. cost =0.147\n",
            "Epoch: 0003 Avg. cost =0.096\n",
            "Epoch: 0004 Avg. cost =0.067\n",
            "Epoch: 0005 Avg. cost =0.050\n",
            "Epoch: 0006 Avg. cost =0.039\n",
            "Epoch: 0007 Avg. cost =0.031\n",
            "Epoch: 0008 Avg. cost =0.024\n",
            "Epoch: 0009 Avg. cost =0.019\n",
            "Epoch: 0010 Avg. cost =0.016\n",
            "Epoch: 0011 Avg. cost =0.020\n",
            "Epoch: 0012 Avg. cost =0.014\n",
            "Epoch: 0013 Avg. cost =0.008\n",
            "Epoch: 0014 Avg. cost =0.010\n",
            "Epoch: 0015 Avg. cost =0.011\n",
            "최적화 완료\n",
            "정확도: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}