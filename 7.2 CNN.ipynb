{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.2 CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/battlerhythm/tensorflow/blob/master/7.2%20CNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "9knrodtFRU5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "1906e281-e78a-4351-da41-6cdbf75de7be"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\",one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-76d2fb65cf6e>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kR6oD_oQRXY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X의 첫번째 차원인 None은 입력 데이터의 개수입니다. 그리고 마지막 차원\n",
        "# 인 1은 특징의 개수로, MNIST데이터는 회색조 이미지라 채널에 색상이 한 개\n",
        "# 뿐이므로 1을 사용하였습니다. 그리고 출력값인 10개의 분류값으로 정의합니다.\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# 컨볼루션계층\n",
        "# 입력층 X와 첫 번째 계층의 가중치 W1을 가지고, 오른쪽과 아래쪽으로 한칸\n",
        "# 씩 움직이는 32개의 커널을 가진 컨볼루션 계층을 만들겟다는 코드입니다. 여기\n",
        "# 서 padding='SAME'은 커널 슬라이딩 시 이미지의 가장 외곽에서 한 칸 밖으로\n",
        "# 움직이는 옵션입니다. 이렇게 하면 이미지의 테두리까지도 조금 더 정확하게 평\n",
        "# 가할 수 있습니다.\n",
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L1 = tf.nn.relu(L1)\n",
        "\n",
        "# 풀링계층\n",
        "# 앞서 만든 컨볼루션 계층을 입력층으로 사용하고, 커널 크기를 2x2로 하는 풀링\n",
        "# 계층을 만듭니다. strides=[1, 2, 2, 1]값은 슬라이딩 시 두 칸씩\n",
        "# 움직이겟다는 옵션입니다.\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "# 3x3크기의 커널 64개로 구성한 컨볼루션 계층과 2x2크기의 풀링 계층으로 구성하였습니다.\n",
        "# 두번째 컨볼루션 계층의 커널인 W2 변수의 구성은 [3, 3, 32, 64] 입니다.\n",
        "# 여기에서 32는 앞서 구성한 첫 번째 컨볼루션 계층의 커널 개수입니다.\n",
        "# 이것은 출력층의 개수이며 또한 첫 번째 컨볼루션 계층이 찾아낸 개수라고 할 수 있겟습니다.\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "# 먼저 10개의 분류는 1차원 배열이므로 차원을 줄이는 단계를 거쳐야 합니다.\n",
        "# 직전의 풀링 계층 크기가 7x7x64이므로, 먼저 tf.reshape함수를 이용해 7x7x64 크기의 1차원 계층으로 만들고,\n",
        "# 이 배열 전체를 최종 출력값의 중간 단계인 256개의 뉴런으로 연결하는 신경망을 만들어줍니다.\n",
        "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
        "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
        "L3 = tf.matmul(L3, W3)\n",
        "L3 = tf.nn.relu(L3)\n",
        "L3 = tf.nn.dropout(L3, keep_prob)\n",
        "\n",
        "# 이제 모델구성의 마지막으로 직전의 은닉층인 L3의 출력값 256개를 받아 최종 출력값인 0~9레이블을 갖는 10개의 출력값을 만듭니다.\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "# optimizer = tf.train.EMSPropOptimizer(0.001, 0.9).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMG5Zqc9RheI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "71ae538e-030d-49c9-e4cb-d739fcc68110"
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(15):\n",
        "    total_cost = 0\n",
        "    \n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "        \n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
        "        total_cost += cost_val\n",
        "        \n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost = ' '{:.3f}'.format(total_cost / total_batch))\n",
        "    \n",
        "print('최적화 완료!')\n",
        "\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "print('정확도:', sess.run(accuracy, feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
        "                                            Y: mnist.test.labels, keep_prob: 1 }))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Avg. cost = 0.345\n",
            "Epoch: 0002 Avg. cost = 0.109\n",
            "Epoch: 0003 Avg. cost = 0.079\n",
            "Epoch: 0004 Avg. cost = 0.063\n",
            "Epoch: 0005 Avg. cost = 0.050\n",
            "Epoch: 0006 Avg. cost = 0.043\n",
            "Epoch: 0007 Avg. cost = 0.036\n",
            "Epoch: 0008 Avg. cost = 0.033\n",
            "Epoch: 0009 Avg. cost = 0.028\n",
            "Epoch: 0010 Avg. cost = 0.027\n",
            "Epoch: 0011 Avg. cost = 0.024\n",
            "Epoch: 0012 Avg. cost = 0.020\n",
            "Epoch: 0013 Avg. cost = 0.020\n",
            "Epoch: 0014 Avg. cost = 0.017\n",
            "Epoch: 0015 Avg. cost = 0.015\n",
            "최적화 완료!\n",
            "정확도: 0.9899\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}